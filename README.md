# ğŸ¤ Offline Video Transcriber â€“ Whisper + Silence Detector

A fully offline Python tool that:
- Converts video/audio â†’ text transcript
- Saves **word-level + sentence-level timestamps**
- Detects **silent pauses** and exports them
- Supports **multiple Whisper model sizes** (base, small, medium, large-v3)
- Creates **separate output folders** per-video & per-model for comparison

---

## ğŸš€ Features

| Feature | Description |
|---------|-------------|
| ğŸ§  Whisper transcription | Uses `faster-whisper` (CTranslate2) for fast CPU inference |
| ğŸ”Š Word timestamps | Every word â†’ start time, end time, confidence |
| ğŸ“ Sentence timestamps | Each spoken segment is extracted |
| ğŸ”‡ Silence Detection | Detects gaps using audio energy analysis |
| ğŸ—‚ Organized Results | Output â†’ `output/<video-name>/<model-name>/...` |
| ğŸ”Œ Offline | No API / No HuggingFace call required |
| ğŸ§ª Multi-model comparison | Run once with `medium`, again with `large` to compare accuracy |

---

## ğŸ§± Folder Structure

