# ðŸŽ™ Phase-1 â€” Audio Transcription Pipeline

This phase converts **any video/audio file** â†’ **clean WAV** â†’ **transcribed text** and generates:

| Output | Description |
|--------|-------------|
| `transcript_words.csv` | Word-level timings & probabilities |
| `transcript_sentences.csv` | Sentence-level transcribed text |
| `silences.csv` | Automatic pause/silence detection |
| `transcript.json` | Combined JSON output |

---

## ðŸ§  Why Phase-1 Exists

Before editing or auto-jump-cut video, we need:
âœ” Clean WAV audio in fixed format  
âœ” Accurate timestamps for each spoken word  
âœ” Sentence segmentation for summary/future NLP  
âœ” Silence duration so Phase-2 can remove gaps  

---

## ðŸª„ High Level Flow

```
INPUT (mp4, mov, wav, mp3)
       â”‚
       â–¼
ffmpeg extracts audio â†’ temp_audio.wav (16-khz, mono)
       â”‚
       â–¼
Whisper (CPU offline â€” base/medium/large)
       â”‚
       â”œâ”€â–¶ word-level CSV
       â”œâ”€â–¶ sentence-level CSV
       â”œâ”€â–¶ transcript.json
       â””â”€â–¶ silence-detection (energy-based) â†’ silences.csv
```

---

## ðŸ§¾ Flowchart Diagram

```
phase1_flowchart.png
```

---

## ðŸŽ¯ Output Folder Structure

```
output/
 â””â”€â”€ video1/
     â”œâ”€â”€ medium/
     â”‚    â”œâ”€â”€ transcript_words.csv
     â”‚    â”œâ”€â”€ transcript_sentences.csv
     â”‚    â”œâ”€â”€ silences.csv
     â”‚    â”œâ”€â”€ transcript.json
     â”‚    â”œâ”€â”€ audio.wav
     â”‚
     â””â”€â”€ large/
          â”œâ”€â”€ ...
```

---

## ðŸš€ CLI Usage

### Single File
```bash
python main.py input/video1.mov
```

### Folder Processing
```bash
python main.py input/
```

---

## ðŸ”§ Change Model (Small/Medium/Large)

Edit `config.json`

```json
{
  "model_size": "medium",
  "language": "en"
}
```

Options:
```
base, small, medium, large
```

---

## ðŸ“Ž Next Step â€” Phase-2

After timestamps exist, **Phase-2 will**:
Cut silent spaces, rebuild edited video, and align audio perfectly.

---
